

# Codex CLI MCP Server Configuration
# Copy this to .env and customize as needed

# ===============================
# MODEL CONFIGURATION
# ===============================

# Codex Model Selection (required)
# Supported models: gpt-5, gpt-5-mini, gpt-5-nano, gpt-5-codex (recommended)
CODEX_MODEL=gpt-5-codex

# Reasoning Level for GPT-5 Models (optional)
# Supported levels: low, medium, high
# Default: medium
CODEX_REASONING=high

# ===============================
# AUTHENTICATION
# ===============================

# OpenAI API Key (required if not using OAuth)
OPENAI_API_KEY=

# OAuth Configuration
# Authentication Method (auto will try OAuth first, fallback to API key)
CODEX_AUTH_METHOD=auto
CODEX_PREFER_OAUTH=true

# OAuth Directory (automatically detected)
# On Windows: Uses USERPROFILE environment variable
# On Linux/Mac: Uses HOME environment variable
# Leave blank for automatic detection
CODEX_AUTH_DIR=

# Optional: Explicit OAuth token (if you have one)
# CHATGPT_OAUTH_TOKEN=your-oauth-token-here

# ===============================
# EXAMPLES
# ===============================

# For maximum performance (gpt-5-codex with high reasoning):
# CODEX_MODEL=gpt-5-codex
# CODEX_REASONING=high

# For balanced performance (recommended for most use cases):
# CODEX_MODEL=gpt-5-codex
# CODEX_REASONING=medium

# For faster responses (lower model with low reasoning):
# CODEX_MODEL=gpt-5-mini
# CODEX_REASONING=low